{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d38d77a-b69f-486d-8eb1-be06d775a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 14:49:20.046765: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-21 14:49:20.080132: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-21 14:49:20.080764: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 14:49:20.864401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import keras \n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f6be14-cfba-4dd4-a14b-3235aba1f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['567auto.ipynb', 'train_values.csv', 'Untitled.ipynb', '.ipynb_checkpoints', 'smallgroup.ipynb', 'Catboost.ipynb', 'AutogluonModels', 'Untitled2.ipynb', 'train_labels.csv', 'Untitled1.ipynb', 'submission.csv', 'test_values.csv', 'submission_format.csv']\n"
     ]
    }
   ],
   "source": [
    "DIR  = \"567/\"\n",
    "SEED = 1881\n",
    "\n",
    "if not os.path.isdir(\"models/\"):\n",
    "    os.makedirs(\"models\")\n",
    "    \n",
    "print(os.listdir(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c9bc99b-d649-40ab-a809-3f692bf907cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(DIR+\"train_values.csv\")\n",
    "train_y = pd.read_csv(DIR+\"train_labels.csv\")\n",
    "test_x  = pd.read_csv(DIR+\"test_values.csv\")\n",
    "sub_csv = pd.read_csv(DIR+\"submission_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64cee934-69dd-4aab-b84e-4ead739ac71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1 = np.array(pd.get_dummies(pd.concat([train_x[\"geo_level_1_id\"], test_x[\"geo_level_1_id\"]])))\n",
    "geo2 = np.array(pd.get_dummies(pd.concat([train_x[\"geo_level_2_id\"], test_x[\"geo_level_2_id\"]])))\n",
    "geo3 = np.array(pd.get_dummies(pd.concat([train_x[\"geo_level_3_id\"], test_x[\"geo_level_3_id\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2a77a70-261f-4a00-8779-7fc721a7de5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347469, 11861)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bda1ad7-c077-4a78-8410-d0f5081d92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NET():\n",
    "    inp = Input((geo3.shape[1],))\n",
    "    i1 = Dense(16, name=\"intermediate\")(inp)\n",
    "    x2 = Dense(geo2.shape[1], activation='sigmoid')(i1)\n",
    "    x1 = Dense(geo1.shape[1], activation='sigmoid')(i1)\n",
    "\n",
    "    model = Model(inp, [x2,x1])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9439ca1-657d-4962-8e8a-87571f705653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2715/2715 - 13s - loss: 0.2047 - dense_12_loss: 0.0531 - dense_13_loss: 0.1516 - 13s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "2715/2715 - 12s - loss: 0.0529 - dense_12_loss: 0.0052 - dense_13_loss: 0.0478 - 12s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "2715/2715 - 10s - loss: 0.0145 - dense_12_loss: 0.0041 - dense_13_loss: 0.0103 - 10s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "2715/2715 - 11s - loss: 0.0066 - dense_12_loss: 0.0035 - dense_13_loss: 0.0031 - 11s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "2715/2715 - 11s - loss: 0.0043 - dense_12_loss: 0.0030 - dense_13_loss: 0.0013 - 11s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "2715/2715 - 13s - loss: 0.0029 - dense_12_loss: 0.0024 - dense_13_loss: 5.8481e-04 - 13s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "2715/2715 - 12s - loss: 0.0020 - dense_12_loss: 0.0017 - dense_13_loss: 3.0124e-04 - 12s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "2715/2715 - 11s - loss: 0.0013 - dense_12_loss: 0.0011 - dense_13_loss: 1.5782e-04 - 11s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "2715/2715 - 11s - loss: 8.2438e-04 - dense_12_loss: 7.3996e-04 - dense_13_loss: 8.4418e-05 - 11s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "2715/2715 - 10s - loss: 5.6182e-04 - dense_12_loss: 5.1506e-04 - dense_13_loss: 4.6761e-05 - 10s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = NET()\n",
    "model.fit(geo3, [geo2, geo1], batch_size=128, epochs=10, verbose=2)\n",
    "model.save(\"geo_embed.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cef690e9-8c1c-42b4-93a3-4f9a03bf0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GEO-Embed Model\n",
    "model = NET()\n",
    "model.load_weights(\"geo_embed.h5\")\n",
    "# \"Extract Intermediate Layer\" Function\n",
    "from keras import backend as K\n",
    "\n",
    "get_int_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[1].output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9991dd2f-d132-4e39-8033-9e9e38878d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract GEO-Embeds for all test data points.\n",
    "# Then assign with test_data\n",
    "\n",
    "out = []\n",
    "for dat in geo3[:260601]:\n",
    "    layer_output = get_int_layer_output([np.array(dat).reshape(1, -1)])[0]\n",
    "    out.append(layer_output)\n",
    "\n",
    "out = np.array(out)\n",
    "out = np.squeeze(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f758838-3190-4d75-9a48-e2c60020712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_x.copy())\n",
    "train_data = train_data.drop(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'], axis=1)\n",
    "train_data = train_data.assign(geo_feat1=out[:,0],\n",
    "                               geo_feat2=out[:,1],\n",
    "                               geo_feat3=out[:,2],  \n",
    "                               geo_feat4=out[:,3],\n",
    "                               geo_feat5=out[:,4],    \n",
    "                               geo_feat6=out[:,5],\n",
    "                               geo_feat7=out[:,6],\n",
    "                               geo_feat8=out[:,7],\n",
    "                               geo_feat9=out[:,8],\n",
    "                               geo_feat10=out[:,9],\n",
    "                               geo_feat11=out[:,10],\n",
    "                               geo_feat12=out[:,11],\n",
    "                               geo_feat13=out[:,12],\n",
    "                               geo_feat14=out[:,13],\n",
    "                               geo_feat15=out[:,14],           \n",
    "                               geo_feat16=out[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20392134-1af3-4a71-8731-855fa0f0165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract GEO-Embeds for all test data points.\n",
    "# Then assign with test_data\n",
    "\n",
    "out = []\n",
    "for dat in geo3[260601:]:\n",
    "    layer_output = get_int_layer_output([np.array(dat).reshape(1, -1)])[0]\n",
    "    out.append(layer_output)\n",
    "\n",
    "out = np.array(out)\n",
    "out = np.squeeze(out)\n",
    "\n",
    "test_data = pd.get_dummies(test_x.copy())\n",
    "test_data = test_data.drop(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'], axis=1)\n",
    "test_data = test_data.assign(geo_feat1=out[:,0],\n",
    "                             geo_feat2=out[:,1],\n",
    "                             geo_feat3=out[:,2],  \n",
    "                             geo_feat4=out[:,3],\n",
    "                             geo_feat5=out[:,4],    \n",
    "                             geo_feat6=out[:,5],\n",
    "                             geo_feat7=out[:,6],\n",
    "                             geo_feat8=out[:,7],\n",
    "                             geo_feat9=out[:,8],\n",
    "                             geo_feat10=out[:,9],\n",
    "                             geo_feat11=out[:,10],\n",
    "                             geo_feat12=out[:,11],\n",
    "                             geo_feat13=out[:,12],\n",
    "                             geo_feat14=out[:,13],\n",
    "                             geo_feat15=out[:,14],           \n",
    "                             geo_feat16=out[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "688d04dd-fb8d-47ae-91f2-676d9d4ed288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_arr(array):\n",
    "    # Get major confidence-scored predicted value.\n",
    "    new_arr = []\n",
    "    for ix, val in enumerate(array):\n",
    "        loc = np.array(val).argmax(axis=0)\n",
    "        k = list(np.zeros((len(val))))\n",
    "        k[loc]=1\n",
    "        new_arr.append(k)\n",
    "        \n",
    "    return np.array(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89cd45cc-6c0d-4141-b0e6-e7cb4ece3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.function_base import delete\n",
    "import pandas as pd\n",
    "y = np.array(train_y[\"damage_grade\"])-1\n",
    "SEED = 1881\n",
    "df = train_data.drop([\"building_id\"], axis=1)\n",
    "x = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68affd6f-73c1-42c9-a42d-ed7f230d2cc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121527\n",
      "[LightGBM] [Info] Number of data points in the train set: 234540, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -2.334953\n",
      "[LightGBM] [Info] Start training from score -0.564079\n",
      "[LightGBM] [Info] Start training from score -1.095713\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.247688\n",
      "[2000]\tvalid_0's multi_error: 0.245578\n",
      "[3000]\tvalid_0's multi_error: 0.245232\n",
      "[4000]\tvalid_0's multi_error: 0.245232\n",
      "[5000]\tvalid_0's multi_error: 0.245616\n",
      "Early stopping, best iteration is:\n",
      "[2718]\tvalid_0's multi_error: 0.244273\n",
      "F1-MICRO SCORE:  0.755726948313572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121454\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -2.338398\n",
      "[LightGBM] [Info] Start training from score -0.564458\n",
      "[LightGBM] [Info] Start training from score -1.094073\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.246201\n",
      "[2000]\tvalid_0's multi_error: 0.244743\n",
      "[3000]\tvalid_0's multi_error: 0.243131\n",
      "[4000]\tvalid_0's multi_error: 0.243246\n",
      "[5000]\tvalid_0's multi_error: 0.244589\n",
      "[6000]\tvalid_0's multi_error: 0.245587\n",
      "Early stopping, best iteration is:\n",
      "[3425]\tvalid_0's multi_error: 0.242556\n",
      "F1-MICRO SCORE:  0.7574443591711435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121432\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.339681\n",
      "[LightGBM] [Info] Start training from score -0.564053\n",
      "[LightGBM] [Info] Start training from score -1.094392\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.253377\n",
      "[2000]\tvalid_0's multi_error: 0.249194\n",
      "[3000]\tvalid_0's multi_error: 0.249923\n",
      "[4000]\tvalid_0's multi_error: 0.250576\n",
      "[5000]\tvalid_0's multi_error: 0.250729\n",
      "Early stopping, best iteration is:\n",
      "[2162]\tvalid_0's multi_error: 0.249002\n",
      "F1-MICRO SCORE:  0.7509976976208749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121410\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.342206\n",
      "[LightGBM] [Info] Start training from score -0.563080\n",
      "[LightGBM] [Info] Start training from score -1.095322\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.249424\n",
      "[2000]\tvalid_0's multi_error: 0.246815\n",
      "[3000]\tvalid_0's multi_error: 0.247199\n",
      "[4000]\tvalid_0's multi_error: 0.246508\n",
      "[5000]\tvalid_0's multi_error: 0.246546\n",
      "[6000]\tvalid_0's multi_error: 0.247928\n",
      "[7000]\tvalid_0's multi_error: 0.247659\n",
      "Early stopping, best iteration is:\n",
      "[4293]\tvalid_0's multi_error: 0.245741\n",
      "F1-MICRO SCORE:  0.7542594013814274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121445\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.339371\n",
      "[LightGBM] [Info] Start training from score -0.564256\n",
      "[LightGBM] [Info] Start training from score -1.094137\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.254221\n",
      "[2000]\tvalid_0's multi_error: 0.250806\n",
      "[3000]\tvalid_0's multi_error: 0.249962\n",
      "[4000]\tvalid_0's multi_error: 0.249847\n",
      "[5000]\tvalid_0's multi_error: 0.249424\n",
      "[6000]\tvalid_0's multi_error: 0.250192\n",
      "[7000]\tvalid_0's multi_error: 0.250806\n",
      "Early stopping, best iteration is:\n",
      "[4329]\tvalid_0's multi_error: 0.248695\n",
      "F1-MICRO SCORE:  0.751304681504221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121390\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.340920\n",
      "[LightGBM] [Info] Start training from score -0.564218\n",
      "[LightGBM] [Info] Start training from score -1.093755\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.253377\n",
      "[2000]\tvalid_0's multi_error: 0.248465\n",
      "[3000]\tvalid_0's multi_error: 0.247966\n",
      "[4000]\tvalid_0's multi_error: 0.247544\n",
      "[5000]\tvalid_0's multi_error: 0.247237\n",
      "[6000]\tvalid_0's multi_error: 0.247084\n",
      "[7000]\tvalid_0's multi_error: 0.24835\n",
      "Early stopping, best iteration is:\n",
      "[4420]\tvalid_0's multi_error: 0.246546\n",
      "F1-MICRO SCORE:  0.7534535686876439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121526\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score -2.334693\n",
      "[LightGBM] [Info] Start training from score -0.564691\n",
      "[LightGBM] [Info] Start training from score -1.094748\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.250614\n",
      "[2000]\tvalid_0's multi_error: 0.246009\n",
      "[3000]\tvalid_0's multi_error: 0.246393\n",
      "[4000]\tvalid_0's multi_error: 0.246278\n",
      "[5000]\tvalid_0's multi_error: 0.246623\n",
      "Early stopping, best iteration is:\n",
      "[2523]\tvalid_0's multi_error: 0.245242\n",
      "F1-MICRO SCORE:  0.7547582501918649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121429\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.340123\n",
      "[LightGBM] [Info] Start training from score -0.563581\n",
      "[LightGBM] [Info] Start training from score -1.095067\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.254566\n",
      "[2000]\tvalid_0's multi_error: 0.249117\n",
      "[3000]\tvalid_0's multi_error: 0.247966\n",
      "[4000]\tvalid_0's multi_error: 0.249885\n",
      "[5000]\tvalid_0's multi_error: 0.249309\n",
      "[6000]\tvalid_0's multi_error: 0.249117\n",
      "Early stopping, best iteration is:\n",
      "[3502]\tvalid_0's multi_error: 0.247544\n",
      "F1-MICRO SCORE:  0.752455871066769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121437\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.343715\n",
      "[LightGBM] [Info] Start training from score -0.563859\n",
      "[LightGBM] [Info] Start training from score -1.093564\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.249117\n",
      "[2000]\tvalid_0's multi_error: 0.245357\n",
      "[3000]\tvalid_0's multi_error: 0.242594\n",
      "[4000]\tvalid_0's multi_error: 0.243208\n",
      "[5000]\tvalid_0's multi_error: 0.243975\n",
      "Early stopping, best iteration is:\n",
      "[2984]\tvalid_0's multi_error: 0.242364\n",
      "F1-MICRO SCORE:  0.7576362240982348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home1/ywang003/.local/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121433\n",
      "[LightGBM] [Info] Number of data points in the train set: 234541, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.337647\n",
      "[LightGBM] [Info] Start training from score -0.564023\n",
      "[LightGBM] [Info] Start training from score -1.095029\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.248503\n",
      "[2000]\tvalid_0's multi_error: 0.245472\n",
      "[3000]\tvalid_0's multi_error: 0.24482\n",
      "[4000]\tvalid_0's multi_error: 0.245395\n",
      "[5000]\tvalid_0's multi_error: 0.245127\n",
      "[6000]\tvalid_0's multi_error: 0.245434\n",
      "Early stopping, best iteration is:\n",
      "[3291]\tvalid_0's multi_error: 0.243668\n",
      "F1-MICRO SCORE:  0.7563315425940138\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "for ix, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    lgb_params = {\n",
    "        \"objective\" : \"multiclass\",\n",
    "        \"num_class\":3,\n",
    "        \"metric\" : \"multi_error\",\n",
    "        \"boosting\": 'gbdt',\n",
    "        \"max_depth\" : -1,\n",
    "        \"num_leaves\" : 33,\n",
    "        \"learning_rate\" : 0.05,\n",
    "        \"feature_fraction\" : 0.4,\n",
    "        \"min_sum_hessian_in_leaf\" : 0.1,\n",
    "        \"max_bin\":8192,\n",
    "        \"verbosity\" : 1,\n",
    "        \"num_threads\":6,\n",
    "        \"seed\": SEED\n",
    "    }\n",
    "\n",
    "    x_train, x_val, y_train, y_val= x[train_index], x[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    val_data   = lgb.Dataset(x_val, label=y_val)\n",
    "\n",
    "    lgb_clf = lgb.train(lgb_params,\n",
    "                        train_data,\n",
    "                        20000,\n",
    "                        valid_sets = [val_data],\n",
    "                        early_stopping_rounds=3000,\n",
    "                        verbose_eval = 1000)\n",
    "\n",
    "    y_pred = lgb_clf.predict(x_val)\n",
    "    print(\"F1-MICRO SCORE: \", f1_score(np.array(pd.get_dummies(y_val)), threshold_arr(y_pred), average='micro'))\n",
    "    lgb_clf.save_model(f'models/model{ix}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "650271c4-4fa6-40e9-bab7-ea222081e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-MICRO SCORE:  0.8081741819870223\n",
      "F1-MICRO SCORE:  0.8178057643677499\n",
      "F1-MICRO SCORE:  0.7991412158817502\n",
      "F1-MICRO SCORE:  0.8285885318935844\n",
      "F1-MICRO SCORE:  0.829018307681091\n",
      "F1-MICRO SCORE:  0.8302462385025383\n",
      "F1-MICRO SCORE:  0.8049124907425527\n",
      "F1-MICRO SCORE:  0.8194174235708994\n",
      "F1-MICRO SCORE:  0.8118541371675472\n",
      "F1-MICRO SCORE:  0.8162900372600259\n"
     ]
    }
   ],
   "source": [
    "# Load all LightGB Models and concatenate.\n",
    "models = []\n",
    "for i in range(10):\n",
    "    model = lgb.Booster(model_file=f'models/model{i}.txt')\n",
    "\n",
    "    y_pred = model.predict(x)\n",
    "    score  = f1_score(np.array(pd.get_dummies(y)), threshold_arr(y_pred), average='micro')\n",
    "    print(\"F1-MICRO SCORE: \", score)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db1a37a1-9990-4089-bbb8-da88ca9fc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(models, x):\n",
    "    # Ensemble K-Fold CV models with adding all confidence score by class.\n",
    "    y_preds = []\n",
    "    \n",
    "    for model in models:\n",
    "        y_pred = model.predict(x)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "    init_y_pred = y_preds[0]\n",
    "    for ypred in y_preds[1:]:\n",
    "        init_y_pred += ypred\n",
    "        \n",
    "    y_pred = threshold_arr(init_y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddba3efa-139a-4b6d-b4b3-dee4fc4e05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data.drop([\"building_id\"], axis=1)\n",
    "x = np.array(df)\n",
    "y_pred = ensemble(models, x)\n",
    "y_pred_label = y_pred.argmax(axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7c5fc34-fca2-44ad-a12f-06a8e065fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv(DIR+'submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=y_pred_label,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission.to_csv('submission_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481cd36-f6be-4557-a201-434aeca395a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
